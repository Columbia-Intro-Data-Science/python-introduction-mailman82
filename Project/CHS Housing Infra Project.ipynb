{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Set \n",
      "\n",
      "Analysis \n",
      "\n",
      "Regression \n",
      "\n",
      "Predictions \n",
      "\n",
      "This notebook is not really set up for this output - running these on the website will work\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mailman82/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:211: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, redirect, render_template, request, url_for\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.cross_validation\n",
    "import statsmodels.api as sm\n",
    "from matplotlib import rcParams\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "#import StringIO\n",
    "#import base64\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "df = pd.read_csv('CHS.csv', index_col=None)\n",
    "df2 = pd.read_csv('CHS_Cat.csv', index_col=None)\n",
    "df_TWN = pd.get_dummies(df['TWN'])\n",
    "df_HDS = pd.get_dummies(df['HDS'])\n",
    "df_final = pd.concat([df[['YR','MSP','PWP','HIR','SCH','INF','WSC','NCR']],df_TWN,df_HDS],axis=1)\n",
    "\n",
    "def bestR2(X, y, X_train, X_test, y_train, y_test):\n",
    "    alphas = np.logspace(-5, -1, 100)\n",
    "    train_errors=[]\n",
    "    coeffs=[]\n",
    "    scores=[]\n",
    "    for alpha in alphas:\n",
    "        regr = Lasso(alpha=alpha)\n",
    "        # Train the model using the training sets\n",
    "        regr.fit(X_train, y_train)\n",
    "        train_errors.append(regr.score(X_train,y_train))\n",
    "        scores.append(regr.score(X_test,y_test))\n",
    "        coeffs.append(regr.coef_)\n",
    "    alpha_optim=alphas[np.argmax(scores)]\n",
    "    regr = Lasso(alpha=alpha_optim)\n",
    "    scores = cross_val_score(regr, X, y, cv=5)\n",
    "\n",
    "    #img = StringIO.StringIO()\n",
    "    #plt.figure(1)\n",
    "    #plt.ylim([-1,1])\n",
    "    #plt.xlabel('lambda')\n",
    "    #plt.ylabel('R^2')\n",
    "    #plt.title('Performance on 5 folds with lambda=' + str(alpha_optim))\n",
    "    #plt.bar(range(1,6),scores)\n",
    "    #plt.savefig(img, format='png')\n",
    "    #img.seek(0)\n",
    "    #plot_url = base64.b64encode(img.getvalue())\n",
    "    #plt.show()\n",
    "    return scores, alpha_optim#, plot_url\n",
    "\n",
    "def GSCV(X,y):\n",
    "    alphas = np.linspace(0.0000001,0.0001,500)\n",
    "    model = Lasso()\n",
    "    grid = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas),cv=3)\n",
    "    grid.fit(X,y)\n",
    "    gbs = grid.best_score_\n",
    "    gbe = grid.best_estimator_.alpha\n",
    "    return grid, gbs, gbe\n",
    "\n",
    "def run_cv(data,X,y,clf_class,**kwargs):\n",
    "    # Construct a kfolds object\n",
    "    kf = KFold(len(y),n_folds=5,shuffle=True)\n",
    "    y_pred = y.copy()\n",
    "    coeffs=[]\n",
    "    # Iterate through folds\n",
    "    for train_index, test_index in kf:\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train = y[train_index]\n",
    "        # Initialize a classifier with key word arguments\n",
    "        clf = clf_class(**kwargs)\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred[test_index] = clf.predict(X_test)\n",
    "        coeffs.append(clf.coef_)\n",
    "    coeffs_avgd = [(coeffs[0][i] + coeffs[1][i] + coeffs[2][i] + coeffs[3][i] + coeffs[4][i])/5 for i in range(0,len(data.columns))]\n",
    "    coeffs_std = [np.std([coeffs[0][i],coeffs[1][i],coeffs[2][i],coeffs[3][i],coeffs[4][i]]) for i in range(0,len(data.columns))]\n",
    "    dfCoeffs = pd.DataFrame({'type':data.columns.values, 'coef':coeffs_avgd, 'std':coeffs_std})\n",
    "    return dfCoeffs\n",
    "\n",
    "def split(feat, data):\n",
    "    X = data.drop([feat],1)\n",
    "    y = data[feat]\n",
    "    scaler = StandardScaler()\n",
    "    X = X.as_matrix().astype(np.float)\n",
    "    X = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    return X,y, X_train, X_test, y_train, y_test\n",
    "\n",
    "def linreg(X_train, X_test, y_train, y_test, data):\n",
    "    # Create regression object\n",
    "    regr = LinearRegression()\n",
    "    # Train the model using the training sets\n",
    "    regr.fit(X_train, y_train)\n",
    "    r2 = regr.score(X_test, y_test)\n",
    "    regr.coef_\n",
    "    coe = pd.DataFrame({'type':list(data.columns), 'coef':regr.coef_})\n",
    "\n",
    "    #img1 = StringIO.StringIO()\n",
    "    #img2 = StringIO.StringIO()\n",
    "    #plt.figure(2)\n",
    "    #plt.ylabel('')\n",
    "    #plt.xlabel('Predicted')\n",
    "    #plt.title('Linear Regression - Training Data')\n",
    "    #plt.scatter(regr.predict(X_train),y_train)\n",
    "    #plt.plot(y_train,y_train)\n",
    "    #plt.show()\n",
    "    #plt.savefig(img1, format='png')\n",
    "    #img1.seek(1)\n",
    "    #trscat = base64.b64encode(img1.getvalue())\n",
    "\n",
    "    #plt.figure(3)\n",
    "    #plt.ylabel('')\n",
    "    #plt.xlabel('Predicted')\n",
    "    #plt.title('Linear Regression - Testing Data')\n",
    "    #plt.scatter(regr.predict(X_test),y_test,label='Actual')\n",
    "    #plt.plot(y_test,y_test)\n",
    "    #plt.show()\n",
    "    #plt.savefig(img2, format='png')\n",
    "    #img2.seek(2)\n",
    "    #tescat = base64.b64encode(img2.getvalue())\n",
    "    return r2, coe#, trscat, tescat\n",
    "\n",
    "def getDs(df):\n",
    "    df_TWN = pd.get_dummies(df['TWN'])\n",
    "    df_HDS = pd.get_dummies(df['HDS'])\n",
    "    df_final = pd.concat([df[['YR','MSP','PWP','HIR','SCH','INF','WSC','NCR']],df_TWN,df_HDS],axis=1)\n",
    "    return df_final\n",
    "\n",
    "def sinCor(Type2, df2):\n",
    "    df_cor = df2.corr()\n",
    "    df_cor_s = df_cor[Type2]\n",
    "    df_cor_s = df_cor_s.to_frame()\n",
    "    table = df_cor_s.round(3)\n",
    "    minval = table[Type2].min()\n",
    "    minfeat = table.loc[table[Type2] == minval].index[0]\n",
    "    tab = table[table[Type2] < 1]\n",
    "    maxval = tab[Type2].max()\n",
    "    maxfeat = tab.loc[tab[Type2] == maxval].index[0]\n",
    "    return table, maxfeat, minfeat\n",
    "\n",
    "def CorMat(table):\n",
    "    minval = table.min()\n",
    "    minfeat = []\n",
    "    maxfeat = []\n",
    "    ind = []\n",
    "    for i in table.index:\n",
    "        ind.append(i)\n",
    "        minfeat.append(table.loc[table[i] == minval[i]].index[0])\n",
    "        maxtab = table[table[i] < 1]\n",
    "        maxv = maxtab[i].max()\n",
    "        maxfeat.append(maxtab.loc[maxtab[i] == maxv].index[0])\n",
    "    df11 = pd.DataFrame({'Category':ind,'Highest Direct':maxfeat,'Highest Inverse':minfeat})\n",
    "    return df11\n",
    "\n",
    "def corFeat(table):\n",
    "    dfs = table.unstack()\n",
    "    dfs = dfs.sort_values()\n",
    "    minval = dfs.min()\n",
    "    min1 = dfs.loc[dfs == minval].index[0]\n",
    "    desa = df2.loc[df2['Category'] == min1[0],'Description'].iloc[0]\n",
    "    desb = df2.loc[df2['Category'] == min1[1],'Description'].iloc[0]\n",
    "    des2 = \"%s and %s \" %(desa,desb)\n",
    "    dfs = dfs[dfs < 1]\n",
    "    maxval = dfs.max()\n",
    "    max1 = dfs.loc[dfs == maxval].index[0]\n",
    "    desa = df2.loc[df2['Category'] == max1[0],'Description'].iloc[0]\n",
    "    desb = df2.loc[df2['Category'] == max1[1],'Description'].iloc[0]\n",
    "    des1 = \"%s and %s \" %(desa,desb)\n",
    "    return max1, min1, des1, des2\n",
    "\n",
    "def pricepred(town, infra, d2):\n",
    "    data = d2[d2['YR'] == 2017]\n",
    "    if infra == \"I526\":\n",
    "        yr = 2020\n",
    "        upd = \"I-526 Extension to Johns and James Island\"\n",
    "        towns = ['CHS', 'KI', 'FOL']\n",
    "        prox = .07\n",
    "        inf = [.05,0,.1]\n",
    "    elif infra == \"NMS\":\n",
    "        yr = 2019\n",
    "        upd = \"North Meeting Street I-26 Exits\"\n",
    "        towns = ['CHS', 'NCH']\n",
    "        prox = .02\n",
    "        inf = [.02,.05]\n",
    "    elif infra == \"CR41\":\n",
    "        yr = 2020\n",
    "        upd = \"North Meeting Street I-26 Exits\"\n",
    "        towns = ['MTP', 'HAN', 'MNC']\n",
    "        prox = .08\n",
    "        inf = [.15,.05,.02]\n",
    "    elif infra == \"HW61\":\n",
    "        yr = 2025\n",
    "        upd = \"HWY 61 Widening\"\n",
    "        towns = ['NCH', 'SUM', 'GC']\n",
    "        prox = .07\n",
    "        inf = [.05,.05,.05]\n",
    "    else:\n",
    "        yr = 2018\n",
    "        data['YR'] = yr\n",
    "        fut = pd.concat([data,d2],axis=0)\n",
    "        upd = \"None\"\n",
    "        scaler = StandardScaler()\n",
    "        fut = fut.as_matrix().astype(np.float)\n",
    "        fut = scaler.fit_transform(fut)\n",
    "        return fut, yr, upd\n",
    "    data['YR'] = yr\n",
    "    j = 0\n",
    "    for t in towns:\n",
    "        data.loc[data[t] == 1, 'PWP'] = data.loc[data[t] == 1, 'PWP'] * (1.0 - prox)\n",
    "        data.loc[data[t] == 1, 'INF'] = data.loc[data[t] == 1, 'INF'] + inf[j]\n",
    "        j = j + 1\n",
    "    fut = pd.concat([data,d2],axis=0)\n",
    "    scaler = StandardScaler()\n",
    "    fut = fut.as_matrix().astype(np.float)\n",
    "    fut = scaler.fit_transform(fut)\n",
    "    return fut, yr, upd\n",
    "\n",
    "\n",
    "'''\n",
    "@app.route('/')\n",
    "def welcome():\n",
    "    return render_template(\"welcome.html\")\n",
    "\n",
    "@app.route('/Data')'''\n",
    "def DataSet():\n",
    "    cat1 = df\n",
    "    cat2 = df2\n",
    "    return cat1, cat2\n",
    "\n",
    "#@app.route('/Analysis_Home', methods = ['GET','POST'])\n",
    "#def AnHo():\n",
    "#    print(\"Starting Analysis\")\n",
    "#    return render_template(\"Analysis_Home.html\")\n",
    "\n",
    "#@app.route('/Analysis', methods = ['GET','POST'])\n",
    "def analy(analy_type):\n",
    "#    if request.method == 'POST':\n",
    "        #analy_type = request.form[\"analyType\"]\n",
    "    if analy_type == \"Infrastructure\":\n",
    "        Type2 = \"INF\"\n",
    "        state = \"Kiawah is a gated island with infrastructure included in their private.\"\n",
    "    elif analy_type == \"Price\":\n",
    "        Type2 = \"MSP\"\n",
    "        state = \"Kiawah Island has the highest mean price.\"\n",
    "    else:\n",
    "        analy_type = \"All Variables\"\n",
    "        Type2 = \"All Variables\"\n",
    "        Desc = \"Correllation Matrix:\"\n",
    "\n",
    "    if len(Type2) == 3:\n",
    "        table, max1, min1 = sinCor(Type2, df)\n",
    "        a1 = \"The feature that has the largest direct corrrelation is: \"\n",
    "        Desc = df2.loc[df2['Category'] == Type2,'Description'].iloc[0]\n",
    "        des1 = df2.loc[df2['Category'] == max1,'Description'].iloc[0]\n",
    "        des2 = df2.loc[df2['Category'] == min1,'Description'].iloc[0]\n",
    "        sans_ki = \"We remove Kiawah Island because, \"\n",
    "        df_nki = df[df['TWN'] != 'KI']\n",
    "        table2, max2, min2 = sinCor(Type2, df_nki)\n",
    "        if max2 == \"YR\":\n",
    "            des3 = \"Year\"\n",
    "        else:\n",
    "            des3 = df2.loc[df2['Category'] == max2,'Description'].iloc[0]\n",
    "        des4 = df2.loc[df2['Category'] == min2,'Description'].iloc[0]\n",
    "        a2 = \"The feature that has the largest inverse corrrelation is: \"\n",
    "        cat = df2\n",
    "        #print(analy_type, Desc, Type2, table, corrst, state, a1, a2, max1, min1, des1, des2, des3, des4, max2, min2, table2, cat)\n",
    "        return \n",
    "    else:\n",
    "        cat = df2\n",
    "        df_cor = df\n",
    "        df_cor = df_cor.corr()\n",
    "        table = df_cor.round(3)\n",
    "        corrst = \"The highest correlation factors by category are (Direct and Inverse):\"\n",
    "        table2 = CorMat(table)\n",
    "        state = \" \"\n",
    "        a1 = \"The features that are most directly correlated are: \"\n",
    "        a2 = \"The features that are most inversely correlated are: \"\n",
    "        max1,min1,des1,des2 = corFeat(table)\n",
    "        max2 = table2['Highest Direct'].value_counts().idxmax()\n",
    "        min2 = table2['Highest Inverse'].value_counts().idxmax()\n",
    "        des3 = df2.loc[df2['Category'] == max2,'Description'].iloc[0]\n",
    "        des4 = df2.loc[df2['Category'] == min2,'Description'].iloc[0]\n",
    "        a3 = \"The feature that most directly affects the dataset is \"\n",
    "        a4 = \"The feature that has the most inverse affect on the dataset is: \"\n",
    "        #print(analy_type, Desc, Type2, table, corrst, state, a1, a2, a3, a4, max1, min1, des1, des2, des3, des4, max2, min2, table2, cat)\n",
    "        return Type2\n",
    "    #else:\n",
    "        #return render_template(\"Analysis_Home.html\")\n",
    "\n",
    "#@app.route('/Prediction_Home', methods = ['GET','POST'])\n",
    "#def PreHo():\n",
    "#    print(\"Starting Prediction\")\n",
    "#    return render_template(\"Prediction_Home.html\")\n",
    "\n",
    "#@app.route('/Price_Pred', methods = ['GET','POST'])\n",
    "def Pred(twn, inf):\n",
    "    #if request.method == 'POST':\n",
    "    town = twn#request.form[\"TWN\"]\n",
    "    infra = inf#request.form[\"INF\"]\n",
    "    tns = df.loc[df['YR'] == 2017, 'TWN']\n",
    "    tns = tns.values\n",
    "    data = getDs(df)\n",
    "    X, y, X_train, X_test, y_train, y_test = split('MSP', data)\n",
    "    d2 = data.drop(['MSP'],1)\n",
    "    r2_init, coe_i = linreg(X_train, X_test, y_train, y_test, d2)\n",
    "    r2_sc, alpha_best = bestR2(X, y, X_train, X_test, y_train, y_test)\n",
    "    if town == \"All\" and infra == \"NONE\":\n",
    "        fut = X\n",
    "        yr = 2018\n",
    "        upd = \"None\"\n",
    "    else:\n",
    "        fut, yr, upd  = pricepred(town, infra, d2)\n",
    "    if r2_sc.max() > r2_init:\n",
    "        regr = Lasso(alpha=alpha_best)\n",
    "        rtype = \"LASSO\"\n",
    "        regr.fit(X_train, y_train)\n",
    "        y_pred = regr.predict(fut)\n",
    "    else:\n",
    "        regr = LinearRegression()\n",
    "        rtype = \"Linear Regression\"\n",
    "        regr.fit(X_train, y_train)\n",
    "        y_pred = regr.predict(fut)\n",
    "    pred = pd.DataFrame({'Town': tns, 'Pred':y_pred[:10]})\n",
    "    if town != \"All\":\n",
    "        cur = df_final.loc[(df_final['YR'] == 2017) & (df_final[town] == 1), 'MSP']\n",
    "        cur = cur.values\n",
    "        cur=cur[0]\n",
    "        towndes = df2.loc[df2['Category'] == town,'Description'].iloc[0]\n",
    "        twn_pred = pred.loc[pred['Town'] == town, 'Pred'].round(1)\n",
    "        twn_pred = twn_pred.values\n",
    "        twn_pred = twn_pred[0]\n",
    "    else:\n",
    "        cur = df_final.loc[df_final['YR'] == 2017, 'MSP']\n",
    "        cur = cur.mean()\n",
    "        towndes = \"All Towns\"\n",
    "        twn_pred = np.average(y_pred[:10])\n",
    "        twn_pred = np.round_(twn_pred,1)\n",
    "    #print(yr,upd,towndes,rtype,cur,twn_pred)\n",
    "    return twn_pred #render_template(\"Price_Pred.html\", yr=yr, upd=upd, town=towndes, rtype=rtype, cur=cur, pred=twn_pred)\n",
    "    #else:\n",
    "        #return render_template(\"Prediction_Home.html\")\n",
    "\n",
    "#@app.route('/Regression')\n",
    "def Regress():\n",
    "    data = getDs(df)\n",
    "    X, y, X_train, X_test, y_train, y_test = split('MSP', data)\n",
    "    d2 = data.drop(['MSP'],1)\n",
    "    r2_init, coe_i = linreg(X_train, X_test, y_train, y_test, d2)\n",
    "    if r2_init > .9:\n",
    "        state = \"The Linear Regression appears to be pretty good, now performing regularization to check further results using Lasso\"\n",
    "    else:\n",
    "        state = \"The Linear Regression is not very good, now perform regularization and Lasso to see if there is improvement\"\n",
    "    r2_sc, alpha_best = bestR2(X, y, X_train, X_test, y_train, y_test)\n",
    "    if r2_sc.max() > r2_init:\n",
    "        state2 = \"The Lasso (L1) method produces better results because the model is shrinking the less important coefficients to zero! Although we don't have a lot of coefficients, there are a few non-important ones\"\n",
    "    else:\n",
    "        state2 = \"The Lasso (L1) method is typically used for lots of features to shrinking the least important to essentially remove, however the features in this model are all relatively important.\"\n",
    "    dfCoeffs = run_cv(d2,X,np.array(y),Lasso,alpha=alpha_best)\n",
    "    grid, gbs, gbe = GSCV(X,y)\n",
    "    if gbs > .9:\n",
    "        result = \"The grid score indicated that this is a good estimate for the model and will work well for predictions.\"\n",
    "    else:\n",
    "        result = \"The grid score may be low, but we will use the model for predictions with some hesitancy on the results.\"\n",
    "    #print(r2_init, r2_sc.max(), coe_i, state, state2, alpha_best, gbs, gbe, dfCoeffs, result)\n",
    "    return result #render_template(\"Regression.html\", linreg_r2=r2_init, regul_r2=r2_sc.max(), linreg_co=coe_i.to_html(), linstate=state, regstate=state2, alpha=alpha_best, regcoe=dfCoeffs.to_html(), plot_url1=BR2, plot_url2=trscat, plot_url3=tescat, gridsc=gbs, gridest=gbe, result=result)\n",
    "\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#    app.run()\n",
    "\n",
    "#Input Area\n",
    "print('Data Set \\n')\n",
    "cat1, cat2 = DataSet()\n",
    "\n",
    "print('Analysis \\n')\n",
    "analy_type = \"MSP\" #Choose 'MSP','INF', or 'All Variables'\n",
    "Type2 = analy(analy_type)\n",
    "\n",
    "print('Regression \\n')\n",
    "result = Regress()\n",
    "\n",
    "print('Predictions \\n')\n",
    "twn = \"CHS\" #Choose Any\n",
    "inf = \"HW61\" #Choose I526, NMS, CR41, HW61\n",
    "twn_pred = Pred(twn, inf)\n",
    "print('This notebook is not really set up for this output - running these on the website will work')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
